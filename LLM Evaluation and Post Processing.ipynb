{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90905ed6-bcc1-439c-afb8-fafbeb72c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai==1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c3906-2ae4-4248-aea9-7fe6027150ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c99bc-fe4c-4a33-92b8-911246918e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403625ff-f857-4e51-adfe-50812687cb0c",
   "metadata": {},
   "source": [
    "# Strategy 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d76aac5-80d2-48bd-b049-d0e17a1d8f65",
   "metadata": {},
   "source": [
    "# Check for offensive words in LLM output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a9913-dea6-4916-ae66-2867a9a04d12",
   "metadata": {},
   "source": [
    "Let us say we have a LLM for a specific use case. Let us call this Task LLM.\n",
    "\n",
    "We can have another LLM to evalulate the output of our Task LLM. Let us call this Evaluation LLM.\n",
    "\n",
    "We can prompt this Evaluation LLM to look for offensive words in the output produced by the Task LLM.\n",
    "\n",
    "To make the Evaluation LLM robust, we will also include a custom offensive word list so that we can guide it to act as per our internal requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24613e0-80a1-49d5-b13b-afdb67fa4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed73920-3aa7-4db9-bbf8-e95b8ac142af",
   "metadata": {},
   "source": [
    "### Step 1 Define custom offensive word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f692c4d-5d6f-4128-9141-c810cd0e4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_word_custom_list = ['knife','weapon']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e5c0c-414b-4014-af7b-2fdb9a5aea46",
   "metadata": {},
   "source": [
    "### Step 2 Define rule_to_find_offense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88dc0683-0d36-467b-8901-e9d683c1c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_to_find_offense =\"\"\"\n",
    "Please review the following sentence and identify any words \n",
    "that are commonly recognized as abusive, offensive, or \n",
    "inappropriate. \n",
    "\n",
    "classify each word as abusive or offensive, or  inappropriate or normal.\n",
    "\n",
    "'Sentence: {actual_sentence}'?\n",
    "\n",
    "Also if any of the words in in the sentence are present in the  offensive_word_custom_list , then\n",
    "classify them as inappropriate\n",
    "\n",
    "'offensive_word_custom_list : {offensive_word_custom_list}\n",
    "\n",
    "Output in the following structure for each of the word in the Sentence.\n",
    "\n",
    "word : classification : reason for classification\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb8218-e88c-4b3d-b364-72781bb6e24e",
   "metadata": {},
   "source": [
    "### Step 3 Get output from Task LLM\n",
    "To make it simpler we will assume below is the output produced by the Task LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe9e506-b7bb-4c66-bd80-85bf8e846a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_sentence = \"hello rude  park threaten knife\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcc430-37c0-4153-8875-97169466777a",
   "metadata": {},
   "source": [
    "### Step 4 Prompt Evaluation LLM to check the output from task LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbbd0759-e0d6-44a5-a875-dcadeda52200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please review the following sentence and identify any words \n",
      "that are commonly recognized as abusive, offensive, or \n",
      "inappropriate. \n",
      "\n",
      "classify each word as abusive or offensive, or  inappropriate or normal.\n",
      "\n",
      "'Sentence: hello rude  park threaten knife'?\n",
      "\n",
      "Also if any of the words in in the sentence are present in the  offensive_word_custom_list , then\n",
      "classify them as inappropriate\n",
      "\n",
      "'offensive_word_custom_list : ['knife', 'weapon']\n",
      "\n",
      "Output in the following structure for each of the word in the Sentence.\n",
      "\n",
      "word : classification : reason for classification\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=os.getenv(\"open_ai_secret_key\"))\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"actual_sentence\", \"offensive_word_custom_list\"],\n",
    "    template=rule_to_find_offense\n",
    "\n",
    ")\n",
    "\n",
    "text = prompt.format(actual_sentence=actual_sentence, offensive_word_custom_list= offensive_word_custom_list)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2daa0f-3155-4045-a260-583da0e1c49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello : normal : Not considered abusive, offensive, or inappropriate.\n",
      "rude : abusive : Contains a derogatory term.\n",
      "park : normal : Not considered abusive, offensive, or inappropriate.\n",
      "threaten : normal : Not considered abusive, offensive, or inappropriate.\n",
      "knife : inappropriate : Present in the offensive_word_custom_list.\n",
      "\n",
      "word : classification : reason for classification\n",
      "hello : normal : Not considered abusive, offensive, or inappropriate.\n",
      "rude : abusive : Contains a derogatory term.\n",
      "park : normal : Not considered abusive, offensive, or inappropriate.\n",
      "threaten : normal : Not considered abusive, offensive, or inappropriate.\n",
      "knife : inappropriate : Present in the offensive_word_custom_list.\n"
     ]
    }
   ],
   "source": [
    "text_llm_chain = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo-instruct',openai_api_key=os.getenv(\"open_ai_secret_key\"))\n",
    "print(text_llm_chain.invoke(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed153e4-3adf-4166-9100-f5be401c458c",
   "metadata": {},
   "source": [
    "#### As we can see from the above ouput, the Evaluation LLM marked words rude as abusive based on its own training.\n",
    "\n",
    "#### Also, it flagged knife as inappropriate based on our custom logic of checking in the offensive_word_custom_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814f1c2-8709-43b2-858a-2f01b73a28df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06d28ff1-9203-4524-a932-ae48ccae734d",
   "metadata": {},
   "source": [
    "# Strategy 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca27b3-ec2a-4f04-9500-9ee9a8eacc44",
   "metadata": {},
   "source": [
    "# Chain of Thought Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69715a49-d46a-4abb-bbf8-d9facf9f5c2f",
   "metadata": {},
   "source": [
    "Let us say we have a LLM for a specific use case. Let us call this Task LLM.\n",
    "\n",
    "We can prompt this Task LLM to explain the chain of thought reasoning for it to have produced that particular output.\n",
    "\n",
    "Along with the output text, we can also store the reason in to a database.\n",
    "\n",
    "We can then perform some analysis on the reasoning given to evaluate if the LLM is performing well.\n",
    "The analysis can be manual to start with, we can have an actual person look at the reasons to check if the reasoning looks good.\n",
    "\n",
    "This can then be automated later to look for some patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b82c4-8f22-4bf9-9ad7-aa130ae9219f",
   "metadata": {},
   "source": [
    "#### Step 1 Set up Chain of thought Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d219a6bf-f640-4017-aa7a-87b04691d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_thought_prompt =\"\"\"\n",
    " Please explain the chain of thought reasoning for giving the answer.\n",
    " format the output in the following structure.\n",
    " \n",
    " QUESTION : {QUESTION}\n",
    " ANSWER: answer\n",
    " REASONING : chain of thought reasoning for giving the answer\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c046d-c512-40e1-9ef8-71a3aaef180f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d209aaf7-2782-4721-bf3e-616aac9d368e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Please explain the chain of thought reasoning for giving the answer.\\n format the output in the following structure.\\n \\n QUESTION : What is the main reason for shopping at walmart \\n ANSWER: answer\\n REASONING : chain of thought reasoning for giving the answer\\n\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"QUESTION\"],\n",
    "    template=chain_of_thought_prompt\n",
    "\n",
    ")\n",
    "\n",
    "text = prompt.format(QUESTION=\"What is the main reason for shopping at walmart \")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c26c6-0c79-4791-8ab4-a619b2319698",
   "metadata": {},
   "source": [
    "#### Step 2 get Answer and Reasoning from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681d3a6d-4ef8-49d2-890b-ca356fafce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION : What is the main reason for shopping at walmart\n",
      "ANSWER: The main reason for shopping at Walmart is its low prices and wide variety of products.\n",
      "\n",
      "REASONING: Walmart is known for its low prices and this is a major factor that attracts customers. The company has a reputation for offering products at a lower cost compared to other retailers. This makes it an attractive option for budget-conscious shoppers who are looking to save money. Additionally, Walmart offers a wide variety of products, from groceries to electronics to clothing, making it a one-stop shop for many people. This convenience factor is another reason why customers choose to shop at Walmart. With a large selection of products at affordable prices, Walmart is able to cater to the needs of a diverse customer base, making it a popular choice for shopping.\n"
     ]
    }
   ],
   "source": [
    "text_llm_chain = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo-instruct',openai_api_key=os.getenv(\"open_ai_secret_key\"))\n",
    "print(text_llm_chain.invoke(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de613a4-8ba5-4bef-9018-fd5a24d6470d",
   "metadata": {},
   "source": [
    "#### As we can see in this simple example, the LLM was able to provide the reasons for coming up with the output. \n",
    "#### It mentioned reasons like save money, a wide variety of products, from groceries to electronics to clothing , affordable prices and so on.\n",
    "\n",
    "#### So, In real life use cases as well, we can use similar prompting technique and get the chain of thought. \n",
    "#### We can then evaluate if it meets our own internal requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa3eac-b31b-45c6-af15-f36a65cea132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4f3e945-04d5-4f49-8612-ddfc8f250068",
   "metadata": {},
   "source": [
    "# Strategy 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0f108-99e3-46f9-b738-b6446bbf9430",
   "metadata": {},
   "source": [
    "# LLM Graded Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaf630a-2930-4110-a978-1ecd3cc91325",
   "metadata": {},
   "source": [
    "Let us say we have a LLM for a specific use case. Let us call this Task LLM.\n",
    "\n",
    "We can have another LLM to evalulate the output of our Task LLM. Let us call this Evaluation LLM.\n",
    "\n",
    "We can prompt this Evaluation LLM to grade the output of the Task LLM.\n",
    "\n",
    "First we prepare a QUESTION and ANSWER pair based on our knowledge about our systems, use case and data.\n",
    "\n",
    "For each question, We ask the Evaluation LLM to compare(grade) the output of the Task LLM with the ANSWERS prepared in the above step.\n",
    "\n",
    "The Evaluation LLM comes up with the grading. If the predictions/outputs from the task LLM are similar to the QUESTION and ANSWER pair we prepared it says the result or grade is CORRECT. If the prediction does not match the QUESTION and ANSWER pair we prepared , it says the result or grade is INCORRECT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef6ba4-900d-4631-bd8c-dfe9e0e4c193",
   "metadata": {},
   "source": [
    "### Step 1 prepare a QUESTION and ANSWER pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a08c6-075a-4de4-a8d9-72bb1e4c83d6",
   "metadata": {},
   "source": [
    "##### For this example, we will purposely set the answer for 3rd question to be incorrect.We will say walmart is very expensive\n",
    "\n",
    "##### We are setting it incorrectly just to show how the LLM evaluation QA chain compares the predictions with QUESTION,ANSWER PAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb8f9297-5cba-4df6-bf38-d244cc71b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "     {\n",
    "         \"QUESTION\": \"What is the main reason for shopping at Best Buy according to the document?\",\n",
    "         \"ANSWER\": \"The main reason for shopping at Best Buy according to the document is to find electronics, computers, appliances, cell phones, video games, and more new tech.\"\n",
    "     },\n",
    "     {\n",
    "         \"QUESTION\": \"What is the main benefit offered by Prime?\",\n",
    "         \"ANSWER\": \"The main benefit offered by Prime is free shipping on millions of items.\"\n",
    "     },\n",
    "         {\n",
    "         \"QUESTION\": \"What is the main reason for shopping at walmart?\",\n",
    "         \"ANSWER\": \"TThe main reason for shopping at walmart is its very expensive.\"\n",
    "     }\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a7685-b400-4b0e-80d2-67ae05cdf5b3",
   "metadata": {},
   "source": [
    "#### If we already stored(say in a database) the output of the Task LLM, we can use it directly.\n",
    "\n",
    "#### But for our simple example, we will get the output on the fly.\n",
    "\n",
    "#### so we will just prepare a list of questions as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94552cbf-f03c-4c46-8ca7-5a0ab8eebd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_questions = [\n",
    "     {\n",
    "         \"QUESTION\": \"What is the main reason for shopping at Best Buy according to the document?\",\n",
    "     },\n",
    "     {\n",
    "         \"QUESTION\": \"What is the main benefit offered by Prime?\",\n",
    "     },\n",
    "         {\n",
    "         \"QUESTION\": \"What is the main reason for shopping at walmart?\",\n",
    "     }\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7dffd-7510-4860-81fd-214d1ba2c6ef",
   "metadata": {},
   "source": [
    "### Step 2 Set up langchain prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce56f8a2-3d62-4e3c-8090-50d6f3371ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['QUESTION'], template='QUESTION: {QUESTION}\\\\ANSWER:')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=os.getenv(\"open_ai_secret_key\"))\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"QUESTION\"],\n",
    "    template=\"QUESTION: {QUESTION}\\ANSWER:\",\n",
    ")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d13d7-5d6d-4c22-818d-11797cabf9c5",
   "metadata": {},
   "source": [
    "### Step 3 Get output from task LLM\n",
    "### If we already stored(say in a database) the output of the Task LLM, we can use it directly.\n",
    "### But for our example, we will get the output on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e899ce3c-dc15-48bc-bb61-fc6ba1e5d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'QUESTION': 'What is the main reason for shopping at Best Buy according to the document?'}, {'QUESTION': 'What is the main benefit offered by Prime?'}, {'QUESTION': 'What is the main reason for shopping at walmart?'}]\n",
      "****************\n",
      "[{'text': ' The main reason for shopping at Best Buy according to the document is the wide selection of products and brands available.'}, {'text': ' The main benefit offered by Prime is access to free and fast shipping on eligible items, as well as access to a wide range of other benefits such as streaming of movies, TV shows, and music, unlimited photo storage, and exclusive deals and discounts.'}, {'text': ' The main reason for shopping at Walmart is typically the low prices and wide selection of products.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_llm_chain = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo-instruct',openai_api_key=os.getenv(\"open_ai_secret_key\"))\n",
    "ch = LLMChain(llm=text_llm_chain, prompt=prompt)\n",
    "#predictions = ch.apply(examples)\n",
    "predictions = ch.apply(example_questions)\n",
    "print (example_questions)\n",
    "print ('****************')\n",
    "print (predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c667e43-6dc9-4926-8b2d-3efc67417cca",
   "metadata": {},
   "source": [
    "### Step 4 Set up langchain QA Evaluation chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01c0556a-e261-4ce0-96f7-95d2f10e035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm_model = \"gpt-3.5-turbo-instruct\"\n",
    "#llm = ChatOpenAI(temperature=0, model=llm_model,openai_api_key=os.getenv(\"open_ai_secret_key\"))\n",
    "llm = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo-instruct',openai_api_key=os.getenv(\"open_ai_secret_key\"))\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d07a37-7f50-4812-aee7-79a88e3c921c",
   "metadata": {},
   "source": [
    "### Step 5 Evaluate / Grade the Task LLM Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0128c84-ef2b-4651-a200-578efdb124a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': ' CORRECT'}, {'results': ' CORRECT'}, {'results': ' INCORRECT'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions, question_key='QUESTION', prediction_key='text', answer_key='ANSWER')\n",
    "graded_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65697875-f09e-465e-a121-9b138ceb3563",
   "metadata": {},
   "source": [
    "#### As we can see from the above grading, the first 2 predictions/outputs from the task LLM are similar to the QUESTION and ANSWER pair we prepared.\n",
    "    \n",
    "#### The 3rd prediction does not match the QUESTION and ANSWER pair we prepared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cdb78f-1a79-4f41-94ca-41d70da1eec7",
   "metadata": {},
   "source": [
    "### Display Question, predictions and grade together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94623d2d-2e31-472c-ab3f-3115d9fd83a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: What is the main reason for shopping at Best Buy according to the document?\n",
      "Real Answer: The main reason for shopping at Best Buy according to the document is to find electronics, computers, appliances, cell phones, video games, and more new tech.\n",
      "Predicted Answer:  The main reason for shopping at Best Buy according to the document is the wide selection of products and brands available.\n",
      "Predicted Grade: CORRECT\n",
      "********************************\n",
      "Example 1:\n",
      "Question: What is the main benefit offered by Prime?\n",
      "Real Answer: The main benefit offered by Prime is free shipping on millions of items.\n",
      "Predicted Answer:  The main benefit offered by Prime is access to free and fast shipping on eligible items, as well as access to a wide range of other benefits such as streaming of movies, TV shows, and music, unlimited photo storage, and exclusive deals and discounts.\n",
      "Predicted Grade: CORRECT\n",
      "********************************\n",
      "Example 2:\n",
      "Question: What is the main reason for shopping at walmart?\n",
      "Real Answer: TThe main reason for shopping at walmart is its very expensive.\n",
      "Predicted Answer:  The main reason for shopping at Walmart is typically the low prices and wide selection of products.\n",
      "Predicted Grade: INCORRECT\n",
      "********************************\n"
     ]
    }
   ],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + examples[i]['QUESTION'])\n",
    "    print(\"Real Answer: \" + examples[i]['ANSWER'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['text'])\n",
    "    print(\"Predicted Grade:\" + graded_outputs[i]['results'])\n",
    "    print('********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186dd08b-59dc-4ec2-9511-705328cb2d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
